ğŸ¯ Objective

To develop an interpretable AI system that can:

Predict student failure risk early

Identify critical learning patterns

Support data-driven educational intervention strategies

ğŸ—‚ Dataset

OULAD â€“ Open University Learning Analytics Dataset

Includes:

Student demographics

Virtual Learning Environment (VLE) activity

Assessment and exam scores

ğŸ— Model Architecture
Layer	Description
Input	22 features (static + temporal)
BiLSTM	Captures bidirectional learning dynamics
Attention	Highlights critical assessment moments
BatchNorm	Stabilizes training
Dropout	Prevents overfitting
Dense (Sigmoid)	Risk probability output
ğŸ“ˆ Results
Metric	Score
Accuracy	0.84
ROC-AUC	0.91
F1 (At-Risk)	0.79
F1 (Success)	0.87

The model successfully identifies students at risk before final failure occurs.

ğŸ” Explainability (XAI)

SHAP (Shapley Additive Explanations) is used for:

Global feature importance

Individual student explanation

Early vs late exam influence comparison

Transparent decision interpretation

ğŸ“‚ Repository Structure
CSE655_FinalProject_OULAD/
â”‚
â”œâ”€â”€ data/           # OULAD dataset files
â”œâ”€â”€ notebooks/      # Training & evaluation notebooks
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

âš™ Installation
pip install -r requirements.txt

â–¶ Usage

Run the main notebook:

notebooks/01_Data_Preprocessing.ipynb


Includes preprocessing, training, evaluation and SHAP explainability.

â­ Key Contributions

Attention-based temporal modeling

Explainable student risk prediction

Interpretable educational analytics pipeline

ğŸ“š References

Lundberg & Lee (2017) â€“ SHAP

Graves & Schmidhuber (2005) â€“ BiLSTM

OULAD â€“ Open University Learning Analytics Dataset
